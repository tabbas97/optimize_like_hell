{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Performance Boosts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going back from Eager Execution\n",
    "\n",
    "- Tf moved to eager execution as part of the migration to TF2. However, as with pytorch, the eager execution can be a major point of performance degradation.\n",
    "- We can use tf.function to perform a similar function on tensor ops as with torch.compile. This exists as a decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 11:12:23.580142: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-27 11:12:24.290670: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/mnt/data/workspace/side_projects/optimize_the_hell_blog/Framework_Samples/tensorflow/venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-05-27 11:12:24.753974: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 11:12:24.781117: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 11:12:24.781351: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 11:12:24.782536: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 11:12:24.782745: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 11:12:24.782941: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 11:12:24.870163: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 11:12:24.870303: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 11:12:24.870404: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 11:12:24.870484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3357 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 Super, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Defining a simple model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "tf.keras.backend.set_floatx('float16')\n",
    "\n",
    "# Enable Tensorcores\n",
    "prec_policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(prec_policy)\n",
    "\n",
    "# Define a simple sequential model with convolutions and linear layers\n",
    "def create_model_internal_activation():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        layers.Conv2D(16, [3, 3], activation='relu', input_shape=(32, 32, 3)),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32, [3, 3], activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1024, activation='relu'),\n",
    "        layers.Dense(10),\n",
    "        layers.Activation('softmax', name = \"preds\") # The output softmax layer should be float32 and must be specified as a constructor argument to the Activation layer\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "internal_model = create_model_internal_activation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_external_activation():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        layers.Conv2D(16, [3, 3], input_shape=(32, 32, 3)),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32, [3, 3]),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1024),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dense(10),\n",
    "        layers.Activation('softmax', name = \"preds\") # The output softmax layer should be float32 and must be specified as a constructor argument to the Activation layer\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Enable Tensorcores\n",
    "prec_policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(prec_policy)\n",
    "\n",
    "external_model = create_model_external_activation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the profiler\n",
    "\n",
    "We will use the tensorflow experimental profiler API since we are only attempting to profile the inference. \n",
    "\n",
    "For training - use the [tf.keras.callbacks.Tensorboard](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Using the profiler start/stop API - Not my preferred method\n",
    "\n",
    "# tf.profiler.experimental.start('logs_internal_activation')\n",
    "# internal_model.predict(tf.random.normal([1, 32, 32, 3]))\n",
    "# tf.profiler.experimental.stop()\n",
    "\n",
    "# Method 2: Using the profiler context manager - My preferred method\n",
    "\n",
    "inp = tf.random.normal([2000, 32, 32, 3])\n",
    "# Move to GPU\n",
    "inp = tf.cast(tf.constant(inp), tf.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1716822745.098845  282445 service.cc:145] XLA service 0x791ff0003120 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1716822745.098868  282445 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2070 Super, Compute Capability 7.5\n",
      "2024-05-27 11:12:25.104773: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-27 11:12:25.136512: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 618ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1716822745.658746  282445 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step \n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 11:12:26.412675: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-05-27 11:12:26.412695: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-05-27 11:12:26.412710: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-05-27 11:12:26.575189: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-05-27 11:12:26.577339: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-05-27 11:12:26.587318: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1025 callback api events and 1023 activity events. \n",
      "2024-05-27 11:12:26.596765: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-05-27 11:12:26.597908: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: logs_internal_activation/plugins/profile/2024_05_27_11_12_26/thameem-GE66.xplane.pb\n",
      "2024-05-27 11:12:26.603026: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-05-27 11:12:26.603136: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 11:12:26.791729: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-05-27 11:12:26.793046: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-05-27 11:12:26.802091: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1021 callback api events and 1022 activity events. \n",
      "2024-05-27 11:12:26.810860: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-05-27 11:12:26.810962: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: logs_external_activation/plugins/profile/2024_05_27_11_12_26/thameem-GE66.xplane.pb\n"
     ]
    }
   ],
   "source": [
    "# Run model once before profiling to ensure the model is built\n",
    "internal_model.predict(inp)\n",
    "external_model.predict(inp) \n",
    "\n",
    "# Internal Activation\n",
    "with tf.profiler.experimental.Profile('logs_internal_activation'):\n",
    "    internal_model.predict(inp)\n",
    "    \n",
    "# External Activation\n",
    "with tf.profiler.experimental.Profile('logs_external_activation'):\n",
    "    external_model.predict(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting to convert the eager graph to a tf.function\n",
    "\n",
    "internal_model_func = tf.function(internal_model)\n",
    "external_model_func = tf.function(external_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 11:12:27.167293: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-05-27 11:12:27.167317: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-05-27 11:12:27.175107: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-05-27 11:12:27.176165: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-05-27 11:12:27.180193: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 26 callback api events and 26 activity events. \n",
      "2024-05-27 11:12:27.180464: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-05-27 11:12:27.180535: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: logs_internal_activation_func/plugins/profile/2024_05_27_11_12_27/thameem-GE66.xplane.pb\n",
      "2024-05-27 11:12:27.180790: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-05-27 11:12:27.180799: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-05-27 11:12:27.188101: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-05-27 11:12:27.189224: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-05-27 11:12:27.193216: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 26 callback api events and 26 activity events. \n",
      "2024-05-27 11:12:27.193560: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-05-27 11:12:27.193651: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: logs_external_activation_func/plugins/profile/2024_05_27_11_12_27/thameem-GE66.xplane.pb\n"
     ]
    }
   ],
   "source": [
    "# Profile the tf.function models\n",
    "# Run graph once before profiling to ensure the function is built\n",
    "internal_model_func(inp)\n",
    "external_model_func(inp)\n",
    "\n",
    "with tf.profiler.experimental.Profile('logs_internal_activation_func'):\n",
    "    internal_model_func(inp)\n",
    "    \n",
    "with tf.profiler.experimental.Profile('logs_external_activation_func'):\n",
    "    external_model_func(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough results\n",
    "\n",
    "Simply wrapping the model in tf.function results in a drop from over 45 ms (Repeated run to exclude first run discrepancy) to < 1.5 ms (Repeated run -> tf.function(model) runs lazily. First run will include the graph build/compile time throwing off results.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggestions from TF Profiler\n",
    "\n",
    "Recommendation for Next Step\n",
    "No step time measured. Therefore we cannot tell where the performance bottleneck is.\n",
    "Tool troubleshooting / FAQ\n",
    "\n",
    "Refer to the TF2 Profiler FAQ\n",
    "Next tools to use for reducing the input time\n",
    "\n",
    "input_pipeline_analyzer (especially Section 3 for the breakdown of input operations on the Host)\n",
    "tf_data_bottleneck_analysis (find the bottleneck in the tf.data input pipeline)\n",
    "trace_viewer (look at the activities on the timeline of each Host Thread near the bottom of the trace view)\n",
    "Next tools to use for reducing the Device time\n",
    "\n",
    "framework_op_stats (identify the time-consuming operations executed on the GPU)\n",
    "trace_viewer (look at the activities on the timeline of each GPU in the trace view)\n",
    "Other useful resources\n",
    "\n",
    "Analyze tf.data performance with the TF Profiler\n",
    "Better performance with the tf.data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to concrete functions\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "input_spec = tf.TensorSpec(\n",
    "    inp.shape, inp.dtype\n",
    ")\n",
    "internal_model_func_concrete = internal_model_func.get_concrete_function(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 11:35:50.602814: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 11:35:50.602977: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-05-27 11:35:50.603049: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-05-27 11:35:50.603309: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 11:35:50.603531: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 11:35:50.603663: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 11:35:50.603863: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 11:35:50.604006: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 11:35:50.604128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3357 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 Super, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "const_graph = convert_variables_to_constants_v2(internal_model_func_concrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 11:36:14.333387: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-05-27 11:36:14.333409: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-05-27 11:36:14.341940: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-05-27 11:36:14.342952: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-05-27 11:36:14.346917: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 14 callback api events and 14 activity events. \n",
      "2024-05-27 11:36:14.347216: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-05-27 11:36:14.347402: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: logs_internal_activation_func_concrete/plugins/profile/2024_05_27_11_36_14/thameem-GE66.xplane.pb\n"
     ]
    }
   ],
   "source": [
    "# Profile the concrete function\n",
    "\n",
    "out = const_graph(inp)\n",
    "\n",
    "with tf.profiler.experimental.Profile('logs_internal_activation_func_concrete'):\n",
    "    const_graph(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Concrete functions ?\n",
    "\n",
    "- The use of concrete functions converts all non-tensor values used in the graph to constants. \n",
    "- Experimentally speaking, it does a much better job of eliminating IDLE time on the device/GPU. This may vary based on the data load pattern. I'll likely make that it's own topic/blog.\n",
    "-  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Performance Notes\n",
    "\n",
    "1. Make dimensions a multiple of 8 if you can. This is shown to make a difference on Tensorcores\n",
    "2. Use bfloat16 if your device supports it. You don't have to worry about precision loss. The dynamic range of bfloat16 is way higher than float16.\n",
    "3. Validate the effect of the input pipeline. More often than not, there is not enough data for the device/GPU to work on. \n",
    "4. The previous point might extend to custom layers if they are not written well. \n",
    "5. Profile before you dive in.\n",
    "\n",
    "## Additional potential dangerous optimizations\n",
    "\n",
    "1. You can disable "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
